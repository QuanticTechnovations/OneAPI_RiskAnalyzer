{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d88d479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from pylab import title, figure, xlabel, ylabel, xticks, bar, legend, axis, savefig\n",
    "from fpdf import FPDF\n",
    "import sdv\n",
    "import sklearn\n",
    "from sdv.constraints import Between\n",
    "from sdv.tabular import GaussianCopula, CopulaGAN, CTGAN, TVAE\n",
    "from sdv.metrics.tabular import KSTest\n",
    "import time \n",
    "import tracemalloc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07aa7d51-0f41-4619-8876-4a0a3ad8bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phik\n",
    "from phik.report import plot_correlation_matrix\n",
    "from phik import report\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "sns.set(rc={'figure.figsize':(7,9)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0253e6-9864-4430-9eb1-d5de4ee238c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing train_test_split from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Importing r2_score module to calculate r square value\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.metrics import log_loss \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Resampling technique\n",
    "#import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Installation syntax\n",
    "#!pip install -U imbalanced-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importing Regression libraries from sklearn\n",
    "from sklearn.linear_model import ARDRegression, Ridge, Lasso, ElasticNet , HuberRegressor\n",
    "from sklearn.linear_model import Lars, PassiveAggressiveRegressor, RANSACRegressor, SGDRegressor, TweedieRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression\n",
    "\n",
    "# Importing Boosting Regression algorithm\n",
    "# If below library is not installed on your system then you can install using following syntax - !pip install lightgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# If below library is not installed on your system then you can install using following syntax - !pip install xgboost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# If below library is not installed on your system then you can install using following syntax - !pip install catboost\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Importing library to save trained model\n",
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c2e8ea2-bc10-4ffa-b0a3-dad78357b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Classification libraries from sklearn\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Importing Boosting Classification algorithm\n",
    "# If below library is not installed on your system then you can install using following syntax - !pip install lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# If below library is not installed on your system then you can install using following syntax - !pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# If below library is not installed on your system then you can install using following syntax - !pip install catboost\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eb56732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_file = 'bank_train_data.csv'\n",
    "#path_to_file = 'classsification_data.csv'\n",
    "#path_to_file = 'commodity 2000-2022.csv'\n",
    "#path_to_file = 'bank_train_data.csv'\n",
    "#path_to_file = 'Acoustic_Extinguisher_Fire_Dataset.csv'\n",
    "#path_to_file = 'house_price.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f728b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_extension_read(path_to_file):\n",
    "    file_extension = path_to_file[path_to_file.rfind('.')+1: ]\n",
    "    \n",
    "    if file_extension == 'xlsx':\n",
    "        return pd.read_excel(path_to_file)\n",
    "    elif file_extension == 'csv':\n",
    "        return pd.read_csv(path_to_file)\n",
    "    elif file_extension == 'json':\n",
    "        return pd.read_json(path_to_file)\n",
    "    elif file_extension == 'txt':\n",
    "        delimiter = input(\"Enter the delimiter if required, otherwise just put it blank: \")\n",
    "        return pd.read_table(path_to_file, delimiter=delimiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "843b3502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = file_extension_read(path_to_file)\n",
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2da07ec8-ed53-4a17-9aed-cc4e75335d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = file_extension_read(path_to_file)\n",
    "#df = df.sample(n=5000, random_state=1)\n",
    "#df.reset_index(drop= True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5dc39cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f630b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_constraints(df):\n",
    "    constraints = []\n",
    "    constraints_dic = {}\n",
    "    number_of_constraints = int(input(\"For how many variables do you want to apply the constraint: \"))\n",
    "    if (number_of_constraints > 0):\n",
    "        for i in range(1, number_of_constraints+1):\n",
    "            type_of_constraint = input(f\"Constraint type for variable {i} [Between, Categorical]: \")\n",
    "            if type_of_constraint == 'Between':\n",
    "                print(\"------------------Between Constraint------------------\")\n",
    "                column = input(\"Enter the targeted column: \")\n",
    "                low = int(input(\"Enter the lower value: \"))\n",
    "                high = int(input(\"Enter the higher value: \"))\n",
    "                constraints_dic[type_of_constraint+str(i)] = [column, low, high]\n",
    "                df = df.loc[(df[column] > low) & (df[column] < high), :]\n",
    "                constraints.append(Between(column = column, low=low, high=high, handling_strategy='transform'))\n",
    "            elif type_of_constraint == 'Categorical':\n",
    "                print(\"------------------Categorical Constraint------------------\")\n",
    "                column = input(\"Enter the targeted column: \")\n",
    "                value_type = input(\"Is the value a string or a number - [String, Number]: \")\n",
    "                if value_type == 'String':\n",
    "                    value = input(\"Enter the targeted values using comma: \")\n",
    "                    value_array = value.split(',')\n",
    "                    constraints_dic[type_of_constraint+str(i)] = [value_array, column]\n",
    "                elif value_type == 'Number':\n",
    "                    value = input(\"Enter the targeted values using comma: \")\n",
    "                    value_array = [int(i) for i in value.split(',')]\n",
    "                    constraints_dic[type_of_constraint+str(i)] = [value_array, column]\n",
    "                df = df.loc[df[column].isin(value_array), :]\n",
    "        return constraints, df, constraints_dic\n",
    "    else:\n",
    "        return constraints, df, constraints_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1be3e0ae-2fed-40ab-9d69-be2766af2294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_model(df_filtered, number_of_samples, constraints, models):\n",
    "    for cols in df_filtered.columns:\n",
    "        #if(df_filtered[cols].dtype == )\n",
    "        #print(df_filtered[cols].dtype)\n",
    "        #print(type(df_filtered[cols].dtype))\n",
    "        \n",
    "        if(df_filtered[cols].dtype == 'uint8'):\n",
    "            df_filtered[cols] = df_filtered[cols].astype('int')\n",
    "            \n",
    "        #print(df_filtered[cols].dtype)\n",
    "        #print(type(df_filtered[cols].dtype))\n",
    "            \n",
    "    \n",
    "    closeness_list = []\n",
    "    for i in models:\n",
    "        model = i(constraints=constraints)\n",
    "        model.fit(df_filtered)\n",
    "        new_data = model.sample(number_of_samples)\n",
    "        closeness = KSTest.compute(df_filtered, new_data)\n",
    "        closeness_list.append(closeness) \n",
    "        continue\n",
    "    max_element = max(closeness_list)\n",
    "    return closeness_list.index(max_element), max_element, new_data, closeness_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed3cde70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Regression Pipeline\n",
    "def mlRegPipeline(df_withTarget, targetColumn_name):\n",
    "     # list of ml algorithm models\n",
    "    algoPool = []\n",
    "    algoName = []\n",
    "\n",
    "    # Dataframe to store model name, model object, r_square value\n",
    "    df_output_cols = ['model_name', 'model_object', 'r_square_value']\n",
    "    df_output = pd.DataFrame(columns=df_output_cols)\n",
    "\n",
    "    # separate the other attributes from the predicting attribute\n",
    "    # Training data without target\n",
    "    df_withTarget = pd.get_dummies(df_withTarget)\n",
    "\n",
    "    X = df_withTarget.drop(targetColumn_name, axis=1)\n",
    "    # Training data target variable\n",
    "    y = df_withTarget[targetColumn_name]\n",
    "\n",
    "    # splitting the training data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=123)\n",
    "\n",
    "    randomForestRegressor_model = RandomForestRegressor()\n",
    "    # Training the Models\n",
    "    print(\"Algo 1\")\n",
    "    random_grid = {'n_estimators': [int(x) for x in np.linspace(start=200, stop=2000, num=100)],\n",
    "                   'max_features': ['auto', 'sqrt'],\n",
    "                   'max_depth': [int(x) for x in np.linspace(10, 110, num=10)],\n",
    "                   'min_samples_split': [2, 5, 10],\n",
    "                   'min_samples_leaf': [1, 2, 4],\n",
    "                   'bootstrap': [True, False]}\n",
    "\n",
    "    randomForestRegressor_model_best = RandomizedSearchCV(estimator=randomForestRegressor_model,\n",
    "                                                          param_distributions=random_grid,\n",
    "                                                          n_iter=25,\n",
    "                                                          cv=3,\n",
    "                                                          verbose=2,\n",
    "                                                          random_state=42,\n",
    "                                                          n_jobs=-1)\n",
    "    algoPool.append(randomForestRegressor_model_best)\n",
    "    algoName.append('RandomForestRegressor')\n",
    "\n",
    "    # CatBoostRegressor Regression\n",
    "    print(\"Algo 2\")\n",
    "    catboost_model = CatBoostRegressor()\n",
    "    random_grid = {'depth': [6, 8, 10],\n",
    "                   'learning_rate': [0.01, 0.05, 0.1],\n",
    "                   'iterations': [30, 50, 100]\n",
    "                   }\n",
    "\n",
    "    catboost_model_best = RandomizedSearchCV(estimator=catboost_model,\n",
    "                                             param_distributions=random_grid,\n",
    "                                             n_iter=25,\n",
    "                                             scoring='r2',\n",
    "                                             cv=3,\n",
    "                                             verbose=2,\n",
    "                                             random_state=42,\n",
    "                                             n_jobs=-1)\n",
    "    algoPool.append(catboost_model_best)\n",
    "    algoName.append('CatBoostRegressor')\n",
    "    \n",
    "    \n",
    "    # XGBRegressor Regression\n",
    "    print(\"Algo 3\")\n",
    "    xgb_regressor_model = XGBRegressor(seed=20)\n",
    "\n",
    "    random_grid = {'max_depth': [3, 5, 6, 10, 15, 20],\n",
    "                   'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "                   'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "                   'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "                   'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "                   'n_estimators': [100, 500, 1000]}\n",
    "\n",
    "    xgb_regressor_model_best = RandomizedSearchCV(estimator=xgb_regressor_model,\n",
    "                                                  param_distributions=random_grid,\n",
    "                                                  scoring='r2',\n",
    "                                                  n_iter=25,\n",
    "                                                  verbose=1)\n",
    "    algoPool.append(xgb_regressor_model_best)\n",
    "    algoName.append('XGBRegressor')\n",
    "\n",
    "    # LGBMRegressor Regression\n",
    "    print(\"Algo 4\")\n",
    "    lightgbm_model = LGBMRegressor()\n",
    "\n",
    "    random_grid = {'n_estimators': [int(x) for x in np.linspace(start=200, stop=2000, num=100)],\n",
    "                   'boosting_type': ['gbdt', 'dart', 'goss', 'rf'],\n",
    "                   'max_depth': [int(x) for x in np.linspace(10, 110, num=10)],\n",
    "                   'min_split_gain': [2, 5, 10],\n",
    "                   'min_child_samples': [int(x) for x in np.linspace(10, 110, num=10)]\n",
    "                   }\n",
    "\n",
    "    lightgbm_model_best = RandomizedSearchCV(estimator=lightgbm_model,\n",
    "                                             param_distributions=random_grid,\n",
    "                                             scoring='r2',\n",
    "                                             n_iter=25,\n",
    "                                             verbose=1)\n",
    "    algoPool.append(lightgbm_model_best)\n",
    "    algoName.append('LGBMRegressor')\n",
    "\n",
    "    # ARD Regression\n",
    "    print(\"Algo 5\")\n",
    "    ard_model = ARDRegression()\n",
    "\n",
    "    random_grid = {'n_iter': [int(x) for x in np.linspace(start=300, stop=2000, num=100)],\n",
    "                   'compute_score': [True, False],\n",
    "                   'threshold_lambda': [int(x) for x in np.linspace(10000, 100000, num=10000)]}\n",
    "\n",
    "    ard_model_best = RandomizedSearchCV(estimator=ard_model,\n",
    "                                        param_distributions=random_grid,\n",
    "                                        scoring='r2',\n",
    "                                        n_iter=25,\n",
    "                                        verbose=1)\n",
    "    algoPool.append(ard_model_best)\n",
    "    algoName.append('ARDRegression')\n",
    "\n",
    "    # Ridge Regression\n",
    "    print(\"Algo 6\")\n",
    "    ridge_model = Ridge()\n",
    "    random_grid = {'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']}\n",
    "\n",
    "    ridge_model_best = RandomizedSearchCV(estimator=ridge_model,\n",
    "                                          param_distributions=random_grid,\n",
    "                                          scoring='r2',\n",
    "                                          n_iter=25,\n",
    "                                          verbose=1)\n",
    "    algoPool.append(ridge_model_best)\n",
    "    algoName.append('Ridge')\n",
    "\n",
    "    # Lasso Regression\n",
    "    print(\"Algo 7\")\n",
    "    lasso_model = Lasso()\n",
    "    random_grid = {'alpha': [int(x) for x in np.linspace(start=1, stop=100, num=10)],\n",
    "                   'normalize': [True, False],\n",
    "                   'max_iter': [int(x) for x in np.linspace(start=1000, stop=10000, num=1000)],\n",
    "                   'selection': ['cyclic', 'random']\n",
    "                   }\n",
    "\n",
    "    lasso_model_best = RandomizedSearchCV(estimator=lasso_model,\n",
    "                                          param_distributions=random_grid,\n",
    "                                          scoring='r2',\n",
    "                                          n_iter=25,\n",
    "                                          verbose=1)\n",
    "    algoPool.append(lasso_model_best)\n",
    "    algoName.append('Lasso')\n",
    "\n",
    "    # ElasticNet Regression\n",
    "    print(\"Algo 8\")\n",
    "    elasticNet_model = ElasticNet()\n",
    "\n",
    "    random_grid = {'alpha': [int(x) for x in np.linspace(start=1, stop=100, num=10)],\n",
    "                   'l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                   'normalize': [True, False],\n",
    "                   'max_iter': [int(x) for x in np.linspace(start=1000, stop=10000, num=1000)],\n",
    "                   'selection': ['cyclic', 'random']\n",
    "                   }\n",
    "\n",
    "    elasticNet_model_best = RandomizedSearchCV(estimator=elasticNet_model,\n",
    "                                               param_distributions=random_grid,\n",
    "                                               scoring='r2',\n",
    "                                               n_iter=25,\n",
    "                                               verbose=1)\n",
    "    algoPool.append(elasticNet_model_best)\n",
    "    algoName.append('ElasticNet')\n",
    "\n",
    "    # Huber Regression\n",
    "    print(\"Algo 9\")\n",
    "    huber_model = HuberRegressor()\n",
    "\n",
    "    random_grid = {'epsilon': [int(x) for x in np.linspace(start=1, stop=50, num=5)],\n",
    "                   'warm_start': [True, False],\n",
    "                   'max_iter': [int(x) for x in np.linspace(start=1000, stop=10000, num=1000)]\n",
    "                   }\n",
    "\n",
    "    huber_model_best = RandomizedSearchCV(estimator=huber_model,\n",
    "                                          param_distributions=random_grid,\n",
    "                                          scoring='r2',\n",
    "                                          n_iter=25,\n",
    "                                          verbose=1)\n",
    "\n",
    "    algoPool.append(huber_model_best)\n",
    "    algoName.append('HuberRegressor')\n",
    "\n",
    "    # Lars Regression\n",
    "    print(\"Algo 10\")\n",
    "    lars_model = Lars()\n",
    "\n",
    "    random_grid = {'n_nonzero_coefs': [int(x) for x in np.linspace(start=500, stop=50000, num=5000)]\n",
    "                   }\n",
    "\n",
    "    lars_model_best = RandomizedSearchCV(estimator=lars_model,\n",
    "                                         param_distributions=random_grid,\n",
    "                                         scoring='r2',\n",
    "                                         n_iter=25,\n",
    "                                         verbose=1)\n",
    "\n",
    "    algoPool.append(lars_model_best)\n",
    "    algoName.append('Lars')\n",
    "\n",
    "    # PassiveAggressiveRegressor Regression\n",
    "    print(\"Algo 11\")\n",
    "    passiveAggressiveRegressor_model = PassiveAggressiveRegressor()\n",
    "\n",
    "    random_grid = {'epsilon': [int(x) for x in np.linspace(start=1, stop=50, num=5)],\n",
    "                   'early_stopping': [True, False],\n",
    "                   'average': [True, False],\n",
    "                   'warm_start': [True, False],\n",
    "                   'validation_fraction': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "                   'max_iter': [int(x) for x in np.linspace(start=1000, stop=10000, num=1000)]\n",
    "                   }\n",
    "\n",
    "    passiveAggressiveRegressor_model_best = RandomizedSearchCV(estimator=passiveAggressiveRegressor_model,\n",
    "                                                               param_distributions=random_grid,\n",
    "                                                               scoring='r2',\n",
    "                                                               n_iter=25,\n",
    "                                                               verbose=1)\n",
    "\n",
    "    algoPool.append(passiveAggressiveRegressor_model_best)\n",
    "    algoName.append('PassiveAggressiveRegressor')\n",
    "\n",
    "    # RANSACRegressor Regression\n",
    "    print(\"Algo 12\")\n",
    "    ransac_Regressor_model = RANSACRegressor()\n",
    "    random_grid = {'max_trials': [int(x) for x in np.linspace(start=100, stop=10000, num=100)],\n",
    "                   'loss': ['absolute_error', 'squared_error'],\n",
    "                   'stop_probability': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                   'max_trials': [int(x) for x in np.linspace(start=100, stop=10000, num=1000)]\n",
    "                   }\n",
    "\n",
    "    ransac_Regressor_model_best = RandomizedSearchCV(estimator=ransac_Regressor_model,\n",
    "                                                     param_distributions=random_grid,\n",
    "                                                     scoring='r2',\n",
    "                                                     n_iter=25,\n",
    "                                                     verbose=1)\n",
    "    algoPool.append(ransac_Regressor_model_best)\n",
    "    algoName.append('RANSACRegressor')\n",
    "\n",
    "    # KernelRidge Regression\n",
    "    print(\"Algo 13\")\n",
    "    kernelRidge_model = KernelRidge()\n",
    "\n",
    "    random_grid = {'alpha': [int(x) for x in np.linspace(start=1, stop=100, num=5)],\n",
    "                   'degree': [1, 2, 3, 4, 5]\n",
    "                   }\n",
    "\n",
    "    kernelRidge_model_best = RandomizedSearchCV(estimator=kernelRidge_model,\n",
    "                                                param_distributions=random_grid,\n",
    "                                                scoring='r2',\n",
    "                                                n_iter=25,\n",
    "                                                verbose=1)\n",
    "\n",
    "    algoPool.append(kernelRidge_model_best)\n",
    "    algoName.append('KernelRidge')\n",
    "\n",
    "    # BayesianRidge Regression\n",
    "    print(\"Algo 14\")\n",
    "    bayesianRidge_model = BayesianRidge()\n",
    "    random_grid = {'lambda_init': [int(x) for x in np.linspace(start=1, stop=100, num=5)],\n",
    "                   'compute_score': [True, False],\n",
    "                   'normalize': [True, False]\n",
    "                   }\n",
    "\n",
    "    bayesianRidge_model_best = RandomizedSearchCV(estimator=bayesianRidge_model,\n",
    "                                                  param_distributions=random_grid,\n",
    "                                                  scoring='r2',\n",
    "                                                  n_iter=25,\n",
    "                                                  verbose=1)\n",
    "    algoPool.append(bayesianRidge_model_best)\n",
    "    algoName.append('BayesianRidge')\n",
    "\n",
    "    # TweedieRegressor Regression\n",
    "    print(\"Algo 15\")\n",
    "    tweedieRegressor_model = TweedieRegressor()\n",
    "\n",
    "    random_grid = {\n",
    "        'alpha': [int(x) for x in np.linspace(start=1, stop=100, num=10)],\n",
    "        'link': ['auto', 'identity', 'log'],\n",
    "        'max_iter': [int(x) for x in np.linspace(start=100, stop=1000, num=100)],\n",
    "        'warm_start': [True, False]\n",
    "    }\n",
    "\n",
    "    tweedieRegressor_model_best = RandomizedSearchCV(estimator=tweedieRegressor_model,\n",
    "                                                     param_distributions=random_grid,\n",
    "                                                     scoring='r2',\n",
    "                                                     n_iter=25,\n",
    "                                                     verbose=1)\n",
    "\n",
    "    algoPool.append(tweedieRegressor_model_best)\n",
    "    algoName.append('TweedieRegressor')\n",
    "\n",
    "    # BaggingRegressor Regression\n",
    "    print(\"Algo 17\")\n",
    "    baggingRegressor_model = BaggingRegressor()\n",
    "\n",
    "    random_grid = {\n",
    "        'n_estimators': [int(x) for x in np.linspace(start=10, stop=1000, num=100)],\n",
    "        'bootstrap': [True, False],\n",
    "        'oob_score': [True, False],\n",
    "        'warm_start': [True, False],\n",
    "        'bootstrap_features': [True, False]\n",
    "    }\n",
    "\n",
    "    baggingRegressor_model_best = RandomizedSearchCV(estimator=baggingRegressor_model,\n",
    "                                                     param_distributions=random_grid,\n",
    "                                                     scoring='r2',\n",
    "                                                     n_iter=25,\n",
    "                                                     verbose=1)\n",
    "\n",
    "    algoPool.append(baggingRegressor_model_best)\n",
    "    algoName.append('BaggingRegressor')\n",
    "\n",
    "    # SGDRegressor Regression\n",
    "    print(\"Algo 18\")\n",
    "    sgd_Regressor_model = SGDRegressor()\n",
    "\n",
    "    random_grid = {\n",
    "        'loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "        'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "        'l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        'max_iter': [int(x) for x in np.linspace(start=1000, stop=10000, num=1000)],\n",
    "        'shuffle': [True, False],\n",
    "        'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "        'validation_fraction': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        'early_stopping': [True, False],\n",
    "        'warm_start': [True, False],\n",
    "        'average': [True, False]\n",
    "    }\n",
    "\n",
    "    sgd_Regressor_model_best = RandomizedSearchCV(estimator=sgd_Regressor_model,\n",
    "                                                  param_distributions=random_grid,\n",
    "                                                  scoring='r2',\n",
    "                                                  n_iter=25,\n",
    "                                                  verbose=1)\n",
    "\n",
    "    algoPool.append(sgd_Regressor_model_best)\n",
    "    algoName.append('SGDRegressor')\n",
    "    \n",
    "    \n",
    "    print(\"algoPool = \", algoPool)\n",
    "    # Training each model using X_train and y_train\n",
    "    algoPool_trained_model = []\n",
    "    time_list = []\n",
    "    all_model_start = time.time()\n",
    "    for number, model in enumerate(algoPool):\n",
    "        print(\"Model = \", number)\n",
    "        print(\"Model name = \", model)\n",
    "        # print(\"Model type = \", type(model))\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # print(\"Model type = \", str(model))\n",
    "        # print(\"Model type = \", type(str(model)))\n",
    "\n",
    "        if (str(model) == 'LinearRegression()'):\n",
    "            algoPool_trained_model.append(model.fit(X_train, y_train, sample_weight=None))\n",
    "        else:\n",
    "            algoPool_trained_model.append(model.fit(X_train, y_train))\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"time_taken \", number, end - start)\n",
    "        time_list.append(end - start)\n",
    "\n",
    "    all_model_end = time.time()\n",
    "    print(\"time_list = \", time_list)\n",
    "    all_model_time = all_model_end - all_model_start\n",
    "    print(\"all_model_time = \", all_model_time)\n",
    "\n",
    "    # algoPool_trained_model = [model.fit(X_train, y_train) for model in algoPool ]\n",
    "\n",
    "    # Storing Model name in dataframe\n",
    "    df_output['Algo_name'] = algoName\n",
    "    df_output['model_name'] = [type(model).__name__ for model in algoPool_trained_model]\n",
    "    # Storing Model object in dataframe\n",
    "    df_output['model_object'] = algoPool_trained_model\n",
    "    # Storing r square value of Model in dataframe\n",
    "    df_output['r_square_value'] = [r2_score(y_test, model.predict(X_test)) for model in algoPool_trained_model]\n",
    "\n",
    "    # Sorting output dataframe by r_square value - 1st Output\n",
    "    df_output.sort_values(by=['r_square_value'], ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "    # Save the model as a pickle in a file - 2nd output\n",
    "    joblib.dump(df_output.loc[0, 'model_object'], 'best_regression_model.pkl')\n",
    "\n",
    "    # Load the model from the file\n",
    "    best_model_from_joblib = joblib.load('best_regression_model.pkl')\n",
    "    best_model_from_joblib = best_model_from_joblib.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Parameter - \", best_model_from_joblib.best_params_)\n",
    "    # Use the loaded model to make predictions\n",
    "    # df_withoutTarget[targetColumn_name] = best_model_from_joblib.predict(df_withoutTarget_afterProcess)\n",
    "\n",
    "    # To save output file in csv - 3rd output\n",
    "    # df_withoutTarget.to_csv('output_test_data.csv', index=False)\n",
    "\n",
    "    return df_output, best_model_from_joblib, best_model_from_joblib.best_params_, df_output.loc[0, 'Algo_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90ea8882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML classification Pipeline\n",
    "def mlClassificationPipeline(df_withTarget, targetColumn_name):\n",
    "    # Algo pool list\n",
    "    algoPool = []\n",
    "    algoName = []\n",
    "\n",
    "    # Dataframe to store model name, model object, r_square value\n",
    "    df_output_cols = ['model_name', 'model_object', 'r_square_value']\n",
    "    df_output = pd.DataFrame(columns=df_output_cols)\n",
    "\n",
    "    #gaussianNB_best = GaussianNB()\n",
    "    #algoPool.append(gaussianNB_best)\n",
    "    #algoName.append('GaussianNB')\n",
    "\n",
    "    logisticRegression = LogisticRegression()\n",
    "    random_grid = {'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "                   'max_iter': [int(x) for x in np.linspace(start=100, stop=1000, num=100)],\n",
    "                   'warm_start': [True, False],\n",
    "                   'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                   'class_weight': ['balanced', None],\n",
    "                   'dual': [True, False]}\n",
    "\n",
    "    logisticRegression_best = RandomizedSearchCV(estimator=logisticRegression,\n",
    "                                                 param_distributions=random_grid,\n",
    "                                                 n_iter=25,\n",
    "                                                 cv=3,\n",
    "                                                 verbose=2,\n",
    "                                                 random_state=42,\n",
    "                                                 scoring='roc_auc',\n",
    "                                                 n_jobs=-1,\n",
    "                                                 refit=True)\n",
    "    algoPool.append(logisticRegression_best)\n",
    "    algoName.append('LogisticRegression')\n",
    "\n",
    "    kNeighborsClassifier = KNeighborsClassifier()\n",
    "    random_grid = {\n",
    "        'n_neighbors': [int(x) for x in np.linspace(start=5, stop=55, num=5)],\n",
    "        'leaf_size': [int(x) for x in np.linspace(start=30, stop=120, num=30)],\n",
    "        'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski', 'wminkowski', 'seuclidean', 'mahalanobis'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    }\n",
    "\n",
    "    kNeighborsClassifier_best = RandomizedSearchCV(estimator=kNeighborsClassifier,\n",
    "                                                   param_distributions=random_grid,\n",
    "                                                   n_iter=25,\n",
    "                                                   cv=3,\n",
    "                                                   verbose=2,\n",
    "                                                   random_state=42,\n",
    "                                                   scoring='roc_auc',\n",
    "                                                   n_jobs=-1,\n",
    "                                                   refit=True)\n",
    "    algoPool.append(kNeighborsClassifier_best)\n",
    "    algoName.append('KNeighborsClassifier')\n",
    "\n",
    "    decisionTreeClassifier = DecisionTreeClassifier()\n",
    "    random_grid = {'criterion': ['gini', 'entropy'],\n",
    "                   'splitter': ['best', 'random'],\n",
    "                   'max_depth': [int(x) for x in np.linspace(start=5, stop=25, num=5)],\n",
    "                   'min_samples_leaf': [int(x) for x in np.linspace(start=1, stop=15, num=3)],\n",
    "                   'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                   'class_weight': ['balanced']\n",
    "                   }\n",
    "\n",
    "    decisionTreeClassifier_best = RandomizedSearchCV(estimator=decisionTreeClassifier,\n",
    "                                                     param_distributions=random_grid,\n",
    "                                                     n_iter=25,\n",
    "                                                     cv=3,\n",
    "                                                     verbose=2,\n",
    "                                                     random_state=42,\n",
    "                                                     scoring='roc_auc',\n",
    "                                                     n_jobs=-1,\n",
    "                                                     refit=True)\n",
    "    algoPool.append(decisionTreeClassifier_best)\n",
    "    algoName.append('DecisionTreeClassifier')\n",
    "    \n",
    "    \n",
    "    baggingClassifier = BaggingClassifier()\n",
    "    random_grid = {\n",
    "        'n_estimators': [int(x) for x in np.linspace(start=10, stop=1000, num=100)],\n",
    "        'bootstrap': [True, False],\n",
    "        'bootstrap_features': [True, False],\n",
    "        'oob_score': [True, False],\n",
    "        'warm_start': [True, False]\n",
    "    }\n",
    "\n",
    "    baggingClassifier_best = RandomizedSearchCV(estimator=baggingClassifier,\n",
    "                                                param_distributions=random_grid,\n",
    "                                                n_iter=25,\n",
    "                                                cv=3,\n",
    "                                                verbose=2,\n",
    "                                                random_state=42,\n",
    "                                                scoring='roc_auc',\n",
    "                                                n_jobs=-1,\n",
    "                                                refit=True)\n",
    "    algoPool.append(baggingClassifier_best)\n",
    "    algoName.append('BaggingClassifier')\n",
    "\n",
    "    gradientBoostingClassifier = GradientBoostingClassifier()\n",
    "    random_grid = {\n",
    "        'loss': ['deviance', 'exponential'],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        'validation_fraction': [0.1, 0.2, 0.3, 0.4],\n",
    "        'n_estimators': [int(x) for x in np.linspace(start=100, stop=1000, num=100)],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'warm_start': [True, False]\n",
    "    }\n",
    "\n",
    "    gradientBoostingClassifier_best = RandomizedSearchCV(estimator=gradientBoostingClassifier,\n",
    "                                                         param_distributions=random_grid,\n",
    "                                                         n_iter=25,\n",
    "                                                         cv=3,\n",
    "                                                         verbose=2,\n",
    "                                                         random_state=42,\n",
    "                                                         scoring='roc_auc',\n",
    "                                                         n_jobs=-1,\n",
    "                                                         refit=True)\n",
    "    algoPool.append(gradientBoostingClassifier_best)\n",
    "    algoName.append('GradientBoostingClassifier')\n",
    "\n",
    "    randomForestClassifier = RandomForestClassifier()\n",
    "    random_grid = {'n_estimators': [int(x) for x in np.linspace(start=200, stop=2000, num=100)],\n",
    "                   'criterion': ['gini', 'entropy'],\n",
    "                   'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                   'max_depth': [int(x) for x in np.linspace(10, 110, num=10)],\n",
    "                   'min_samples_split': [2, 5, 10],\n",
    "                   'min_samples_leaf': [1, 2, 4],\n",
    "                   'bootstrap': [True, False],\n",
    "                   'warm_start': [True, False],\n",
    "                   'class_weight': ['balanced', 'balanced_subsample']\n",
    "                   }\n",
    "\n",
    "    randomForestClassifier_best = RandomizedSearchCV(estimator=randomForestClassifier,\n",
    "                                                     param_distributions=random_grid,\n",
    "                                                     n_iter=25,\n",
    "                                                     cv=3,\n",
    "                                                     verbose=2,\n",
    "                                                     random_state=42,\n",
    "                                                     scoring='roc_auc',\n",
    "                                                     n_jobs=-1,\n",
    "                                                     refit=True)\n",
    "    algoPool.append(randomForestClassifier_best)\n",
    "    algoName.append('RandomForestClassifier')\n",
    "\n",
    "    adaBoostClassifier = AdaBoostClassifier()\n",
    "    random_grid = {'n_estimators': [int(x) for x in np.linspace(start=50, stop=1000, num=50)],\n",
    "                   'algorithm': ['SAMME', 'SAMME.R'],\n",
    "                   'learning_rate': [int(x) for x in np.linspace(1, 20, num=3)]\n",
    "\n",
    "                   }\n",
    "\n",
    "    adaBoostClassifier_best = RandomizedSearchCV(estimator=adaBoostClassifier,\n",
    "                                                 param_distributions=random_grid,\n",
    "                                                 n_iter=25,\n",
    "                                                 cv=3,\n",
    "                                                 verbose=2,\n",
    "                                                 random_state=42,\n",
    "                                                 scoring='roc_auc',\n",
    "                                                 n_jobs=-1,\n",
    "                                                 refit=True)\n",
    "    algoPool.append(adaBoostClassifier_best)\n",
    "    algoName.append('AdaBoostClassifier')\n",
    "\n",
    "    mLPClassifier = MLPClassifier()\n",
    "    random_grid = {\n",
    "        'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "        'max_iter': [int(x) for x in np.linspace(200, 1000, num=100)],\n",
    "        'shuffle': [True, False],\n",
    "        'warm_start': [True, False],\n",
    "        'nesterovs_momentum': [True, False],\n",
    "        'early_stopping': [True, False]\n",
    "\n",
    "    }\n",
    "\n",
    "    mLPClassifier_best = RandomizedSearchCV(estimator=mLPClassifier,\n",
    "                                            param_distributions=random_grid,\n",
    "                                            n_iter=25,\n",
    "                                            cv=3,\n",
    "                                            verbose=2,\n",
    "                                            random_state=42,\n",
    "                                            scoring='roc_auc',\n",
    "                                            n_jobs=-1,\n",
    "                                            refit=True)\n",
    "    algoPool.append(mLPClassifier_best)\n",
    "    algoName.append('MLPClassifier')\n",
    "\n",
    "    xGBClassifier = XGBClassifier()\n",
    "    random_grid = {'max_depth': [3, 5, 6, 10, 15, 20],\n",
    "                   'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "                   'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "                   'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "                   'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "                   'n_estimators': [100, 500, 1000]}\n",
    "\n",
    "    xGBClassifier_best = RandomizedSearchCV(estimator=xGBClassifier,\n",
    "                                            param_distributions=random_grid,\n",
    "                                            n_iter=25,\n",
    "                                            cv=3,\n",
    "                                            verbose=2,\n",
    "                                            random_state=42,\n",
    "                                            scoring='roc_auc',\n",
    "                                            n_jobs=-1,\n",
    "                                            refit=True)\n",
    "    algoPool.append(xGBClassifier_best)\n",
    "    algoName.append('XGBClassifier')\n",
    "\n",
    "    lGBMClassifier = LGBMClassifier()\n",
    "    random_grid = {'n_estimators': [int(x) for x in np.linspace(start=100, stop=1000, num=100)],\n",
    "                   'boosting_type': ['gbdt', 'dart', 'goss', 'rf'],\n",
    "                   'max_depth': [int(x) for x in np.linspace(10, 110, num=10)],\n",
    "                   'min_split_gain': [2, 5, 10],\n",
    "                   'min_child_samples': [int(x) for x in np.linspace(10, 110, num=10)]\n",
    "                   }\n",
    "\n",
    "    lGBMClassifier_best = RandomizedSearchCV(estimator=lGBMClassifier,\n",
    "                                             param_distributions=random_grid,\n",
    "                                             n_iter=25,\n",
    "                                             cv=3,\n",
    "                                             verbose=2,\n",
    "                                             random_state=42,\n",
    "                                             scoring='roc_auc',\n",
    "                                             n_jobs=-1,\n",
    "                                             refit=True)\n",
    "    algoPool.append(lGBMClassifier_best)\n",
    "    algoName.append('LGBMClassifier')\n",
    "\n",
    "    catBoostClassifier = CatBoostClassifier()\n",
    "    random_grid = {'depth': [6, 8, 10],\n",
    "                   'learning_rate': [0.01, 0.05, 0.1],\n",
    "                   'iterations': [30, 50, 100]\n",
    "                   }\n",
    "\n",
    "    catBoostClassifier_best = RandomizedSearchCV(estimator=catBoostClassifier,\n",
    "                                                 param_distributions=random_grid,\n",
    "                                                 n_iter=25,\n",
    "                                                 cv=3,\n",
    "                                                 verbose=2,\n",
    "                                                 random_state=42,\n",
    "                                                 scoring='roc_auc',\n",
    "                                                 n_jobs=-1,\n",
    "                                                 refit=True)\n",
    "    algoPool.append(catBoostClassifier_best)\n",
    "    algoName.append('CatBoostClassifier')\n",
    "    \n",
    "\n",
    "    df_withTarget = pd.get_dummies(df_withTarget)\n",
    "\n",
    "    X = df_withTarget.drop(targetColumn_name, axis=1)\n",
    "    # Training data target variable\n",
    "    y = df_withTarget[targetColumn_name]\n",
    "\n",
    "    # splitting the training data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    oversample = SMOTE()\n",
    "    X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Training each model using X_train and y_train\n",
    "\n",
    "    time_list = []\n",
    "    algoPool_trained_model = []\n",
    "    all_model_start = time.time()\n",
    "    for number, model in enumerate(algoPool):\n",
    "        print(\"Model = \", number)\n",
    "        print(\"Model name = \", model)\n",
    "        # print(\"Model type = \", type(model))\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # print(\"Model type = \", str(model))\n",
    "        # print(\"Model type = \", type(str(model)))\n",
    "\n",
    "        algoPool_trained_model.append(model.fit(X_train, y_train))\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"time_taken \", number, end - start)\n",
    "        time_list.append(end - start)\n",
    "    all_model_end = time.time()\n",
    "    print(\"time_list = \", time_list)\n",
    "    all_model_time = all_model_end - all_model_start\n",
    "    print(\"all_model_time = \", all_model_time)\n",
    "\n",
    "    # algoPool_trained_model = [model.fit(X_train, y_train) for model in algoPool ]\n",
    "\n",
    "    df_output = pd.DataFrame()\n",
    "    # Storing Model name in dataframe\n",
    "    df_output['Algo_name'] = algoName\n",
    "    df_output['model_name'] = [type(model).__name__ for model in algoPool_trained_model]\n",
    "    # Storing Model object in dataframe\n",
    "    df_output['model_object'] = algoPool_trained_model\n",
    "    # Storing model accuracy value of Model in dataframe\n",
    "    df_output['accuracy'] = [accuracy_score(y_test, model.predict(X_test)) for model in algoPool_trained_model]\n",
    "\n",
    "    # Storing model f1_score value of Model in dataframe\n",
    "    df_output['f1_score'] = [f1_score(y_test, model.predict(X_test)) for model in algoPool_trained_model]\n",
    "\n",
    "    # Storing model log_loss value of Model in dataframe\n",
    "    df_output['log_loss_score'] = [log_loss(y_test, model.predict(X_test), eps=1e-15) for model in\n",
    "                                   algoPool_trained_model]\n",
    "\n",
    "    df_output['roc_auc_score'] = [roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]) for model in\n",
    "                                  algoPool_trained_model]\n",
    "\n",
    "    # Sorting output dataframe by roc_auc_score value - 1st Output\n",
    "    df_output.sort_values(by=['accuracy'], ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "    # Save the model as a pickle in a file - 2nd output\n",
    "    joblib.dump(df_output.loc[0, 'model_object'], 'best_classification_model.pkl')\n",
    "\n",
    "    # Load the model from the file\n",
    "    best_model_from_joblib = joblib.load('best_classification_model.pkl')\n",
    "    best_model_from_joblib = best_model_from_joblib.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Parameter - \", best_model_from_joblib.best_params_)\n",
    "\n",
    "    # To save output file in csv - 3rd output\n",
    "    # df_output.to_csv('algorithm_output.csv', index=False)\n",
    "\n",
    "    return df_output, best_model_from_joblib, best_model_from_joblib.best_params_, df_output.loc[0, 'Algo_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a101a653-18d7-4184-91b8-35f8f6887319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_simulation(df, target_variable, number_of_samples, reg, best_r2, threshold_value, min_value_deviation, max_value_deviation):\n",
    "    #df = pd.get_dummies(df)\n",
    "    # X = df.iloc[:, 0:len(df.columns.tolist())-1].values\n",
    "    # y = df.iloc[:, -1].values\n",
    "\n",
    "    X = df.drop(target_variable, axis=1)\n",
    "    y = df[target_variable]\n",
    "\n",
    "    #     output_df, reg = mlRegPipeline(df, target_variable)\n",
    "    X = pd.get_dummies(X)\n",
    "    y_pred = reg.predict(X)\n",
    "    print(\"R2 Score: \", best_r2)\n",
    "\n",
    "    sample_df = df.copy()\n",
    "    sample_df.drop(columns=target_variable, inplace=True)\n",
    "    df_predicted = pd.DataFrame(X, columns=sample_df.columns.tolist())\n",
    "    df_predicted[target_variable] = y_pred\n",
    "\n",
    "    threshold_constraint = (abs(min_value_deviation) + abs(max_value_deviation))/ 2\n",
    "    threshold_value = int(threshold_value)\n",
    "    min_value_deviation = int(min_value_deviation)\n",
    "    max_value_deviation = int(max_value_deviation)\n",
    "    min_value = threshold_value + (min_value_deviation / 100) * threshold_value\n",
    "    max_value = threshold_value + (max_value_deviation / 100) * threshold_value\n",
    "    df_predicted_filtered = df_predicted.loc[(df_predicted[target_variable] >= min_value) & (df_predicted[target_variable] <= max_value), :].copy()\n",
    "\n",
    "    #     reg = train_test_reg(df_predicted_filtered, reg)\n",
    "\n",
    "    df_test = df_predicted_filtered.copy()\n",
    "    df_test.drop(columns=target_variable, inplace=True)\n",
    "\n",
    "    models = [GaussianCopula, CopulaGAN, CTGAN, TVAE]\n",
    "    models_string = ['GaussianCopula', 'CopulaGAN', 'CTGAN', 'TVAE']\n",
    "    \n",
    "    user_time_start = time.time()\n",
    "    constraints, df_filtered, constraints_dic = user_constraints(df_test)\n",
    "    user_time_end = time.time()\n",
    "    user_time = user_time_end - user_time_start\n",
    "    \n",
    "\n",
    "    if len(df_filtered) <= 10:\n",
    "        model = GaussianCopula(constraints=constraints)\n",
    "        model.fit(df_filtered)\n",
    "        df_filtered = model.sample(20)\n",
    "\n",
    "    index, max_element, new_data, models_value_list = optimized_model(df_filtered,\n",
    "                                                                                         number_of_samples,\n",
    "                                                                                         constraints, models)\n",
    "    print(\"\\nModel Used: {}\".format(models_string[index]))\n",
    "    max_element = max_element * 100\n",
    "    print(\"Closeness to the real value dataset: {:.2f}%\\n\".format(max_element))\n",
    "\n",
    "    X_temp = pd.get_dummies(new_data)\n",
    "    y_pred_close = reg.predict(X_temp)\n",
    "    #     len(y_pred_close)\n",
    "    y_pred_close_filtered = y_pred_close[(y_pred_close >= min_value) & (y_pred_close <= max_value)]\n",
    "    #     print(len(y_pred_close_filtered))\n",
    "\n",
    "    deviation_histo = []\n",
    "    for i in y_pred_close_filtered:\n",
    "        deviation = (i - threshold_value) / threshold_value\n",
    "        deviation_histo.append(deviation)\n",
    "    deviation_histo_original = []\n",
    "    for i in y_pred_close:\n",
    "        deviation = (i - threshold_value) / threshold_value\n",
    "        deviation_histo_original.append(deviation)\n",
    "    #     print(len(deviation_histo))\n",
    "    plt.clf()\n",
    "    sns.histplot(data=deviation_histo, kde=True).set(title=\"Positive and negative deviation from the estimation value - Filtered Data\")\n",
    "    plt.clf()\n",
    "    sns.histplot(data=deviation_histo_original, kde=True).set(title=\"Positive and negative deviation from the estimation value - Full Samples\")\n",
    "    plt.clf()\n",
    "    sns.histplot(data=y_pred_close, kde=True).set(title=\"Distribution of the synthetic dataset\")\n",
    "\n",
    "    true_percentage = (len(deviation_histo) / number_of_samples)\n",
    "    true_percentage *= true_percentage\n",
    "    risk_percentage = (1 - true_percentage) * 100\n",
    "    print(\"Estimated Risk calculated by the simulation program: {:.2f}%\".format(risk_percentage))\n",
    "    return new_data, threshold_value, threshold_constraint, min_value, max_value, max_element, number_of_samples, models_string[index], deviation_histo, deviation_histo_original, y_pred_close, y_pred_close_filtered, true_percentage, constraints_dic, user_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8c460f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_simulation(df, target_variable, number_of_samples, clf, best_accuracy, threshold_value_call, less_great):\n",
    "    #df = pd.get_dummies(df)\n",
    "\n",
    "    print(\"clf = \", clf)\n",
    "    print(\"type(clf) = \", type(clf))\n",
    "\n",
    "    for cols in df.columns:\n",
    "        # if(df_filtered[cols].dtype == )\n",
    "        print(df[cols].dtype)\n",
    "        print(type(df[cols].dtype))\n",
    "\n",
    "        if (df[cols].dtype == 'uint8'):\n",
    "            df[cols] = df[cols].astype('int')\n",
    "\n",
    "        print(df[cols].dtype)\n",
    "        print(type(df[cols].dtype))\n",
    "\n",
    "    X = df.drop(target_variable, axis=1)\n",
    "    y = df[target_variable]\n",
    "\n",
    "    X_get_dummies = pd.get_dummies(X)\n",
    "    sc = StandardScaler()\n",
    "    X_sc = sc.fit_transform(X_get_dummies)\n",
    "\n",
    "    y_pred = clf.predict_proba(X_sc)[:, 1]\n",
    "    y_pred = list(y_pred)\n",
    "    y_pred = [i * 100 for i in y_pred]\n",
    "\n",
    "    sample_df = df.copy()\n",
    "    sample_df.drop(columns=target_variable, inplace=True)\n",
    "    df_predicted = pd.DataFrame(X, columns=sample_df.columns.tolist())\n",
    "    df_predicted[target_variable] = y_pred\n",
    "\n",
    "    print(\"1 df_predicted[target_variable]\", df_predicted[target_variable])\n",
    "    threshold_value = threshold_value_call\n",
    "    #threshold_constraint = int(input(\"Agreed deviation percentage: \"))\n",
    "    #min_value = threshold_value - (threshold_constraint / 100) * threshold_value\n",
    "    #max_value = threshold_value + (threshold_constraint / 100) * threshold_value\n",
    "    #print(\"min_value = \", min_value)\n",
    "    #print(\"max_value = \", max_value)\n",
    "\n",
    "    if(less_great == 'Greater than'):\n",
    "        df_predicted_filtered = df_predicted.loc[(df_predicted[target_variable] >= threshold_value), :].copy()\n",
    "    elif(less_great == 'Less than'):\n",
    "        df_predicted_filtered = df_predicted.loc[(df_predicted[target_variable] <= threshold_value),:].copy()\n",
    "\n",
    "    df_predicted_filtered[target_variable] = [1 if i > 50 else 0 for i in df_predicted_filtered[target_variable]]\n",
    "    print(\"2 df_predicted_filtered[target_variable]\", df_predicted_filtered[target_variable])\n",
    "\n",
    "    #clf = train_test_clf(df_predicted_filtered, clf)\n",
    "\n",
    "    df_test = df_predicted_filtered.copy()\n",
    "    df_test.drop(columns=target_variable, inplace=True)\n",
    "\n",
    "    models = [GaussianCopula, CopulaGAN, CTGAN, TVAE]\n",
    "    models_string = ['GaussianCopula', 'CopulaGAN', 'CTGAN', 'TVAE']\n",
    "  \n",
    "    user_time_start = time.time()\n",
    "    constraints, df_filtered, constraints_dic = user_constraints(df_test)\n",
    "    user_time_end = time.time()\n",
    "    user_time = user_time_end - user_time_start\n",
    "    \n",
    "\n",
    "    if len(df_filtered) <= 10:\n",
    "        model = GaussianCopula(constraints=constraints)\n",
    "        model.fit(df_filtered)\n",
    "        df_filtered = model.sample(20)\n",
    "\n",
    "    index, max_element, new_data, models_value_list = optimized_model(df_filtered, number_of_samples,\n",
    "                                                                                         constraints, models)\n",
    "    print(\"\\nModel Used: {}\".format(models_string[index]))\n",
    "    max_element = max_element * 100\n",
    "    print(\"Closeness to the real value dataset: {:.2f}%\\n\".format(max_element))\n",
    "\n",
    "    print(\"3 clf = \", clf)\n",
    "    print(\"3 type(clf) = \", type(clf))\n",
    "\n",
    "    #st.write('new_data.values: ', type(new_data))\n",
    "\n",
    "    X_after = pd.get_dummies(new_data)\n",
    "    #st.write('X.columns: ', X.columns)\n",
    "    #st.write('X_get_dummies.columns: ', X_get_dummies.columns)\n",
    "    #st.write('X_after.columns: ', X_after.columns)\n",
    "    X_after = sc.transform(X_after)\n",
    "    #X_after = pd.get_dummies(X_after)\n",
    "    y_pred_close = clf.predict_proba(X_after)[:, 1]\n",
    "\n",
    "    y_pred_close = [i * 100 for i in y_pred_close]\n",
    "\n",
    "    if (less_great == 'Greater than'):\n",
    "        y_pred_close_filtered = [i for i in y_pred_close if i >= threshold_value]\n",
    "        #y_pred_close_filtered = y_pred_close[for i in y_pred_close >= threshold_value]\n",
    "    elif (less_great == 'Less than'):\n",
    "        y_pred_close_filtered = [i for i in y_pred_close if i <= threshold_value]\n",
    "\n",
    "\n",
    "    #     len(y_pred_close)\n",
    "    #y_pred_close_filtered = y_pred_close[(y_pred_close >= min_value) & (y_pred_close <= max_value)]\n",
    "    #     print(len(y_pred_close_filtered))\n",
    "\n",
    "    deviation_histo = []\n",
    "    for i in y_pred_close_filtered:\n",
    "        deviation = (i - threshold_value) / threshold_value\n",
    "        deviation_histo.append(deviation)\n",
    "    deviation_histo_original = []\n",
    "    for i in y_pred_close:\n",
    "        deviation = (i - threshold_value) / threshold_value\n",
    "        deviation_histo_original.append(deviation)\n",
    "    #     print(len(deviation_histo))\n",
    "    plt.clf()\n",
    "    sns.histplot(data=deviation_histo, kde=True).set(title=\"Positive and negative deviation from the estimation value\")\n",
    "\n",
    "    true_percentage = (len(deviation_histo) / number_of_samples)\n",
    "    risk_percentage = (1 - true_percentage) * 100\n",
    "    print(\"Estimated Risk calculated by the simulation program: {:.2f}%\".format(risk_percentage))\n",
    "    return new_data, threshold_value, max_element, number_of_samples, models_string[index], deviation_histo, deviation_histo_original, y_pred_close, y_pred_close_filtered, true_percentage, constraints_dic, user_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0da8449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb98e378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_process(df, target, sample_size, threshold_value, min_value, max_value, model_present, model_obj, less_great, project_name):\n",
    "    time_list = []\n",
    "    memory_usage = []\n",
    "\n",
    "    begin = time.time()\n",
    "    tracemalloc.start()\n",
    "\n",
    "    if (df[target].nunique() > 2):\n",
    "        if(model_present == 'no'):\n",
    "            output_df, reg, best_parameter, best_model_name = mlRegPipeline(df, target)\n",
    "            #best_r2 = output_df['r_square_value'][0]\n",
    "            best_r2 = 'NA'\n",
    "        else:\n",
    "            reg = model_obj\n",
    "            #best_r2 = r2_score(df[target], model_obj.predict(df.drop(target, axis=1)))\n",
    "            best_r2 = 'NA'\n",
    "        generated_data, threshold_value, threshold_constraint, min_value, max_value, closeness, number_of_samples, model_value, deviation_histo, deviation_histo_original, y_pred_close, y_pred_close_filtered, true_percentage, constraints_dic, user_time = regression_simulation(df, target, sample_size, reg, best_r2, threshold_value, min_value, max_value)\n",
    "        type_of_problem = 'regression'\n",
    "        #generated_data.to_csv('generated_data.csv', index=False)\n",
    "\n",
    "        #st.write('before generated_data.columns: ', generated_data.columns)\n",
    "        #generated_data = undummify(generated_data)\n",
    "        #st.write('after generated_data.columns: ', generated_data.columns)\n",
    "    else:\n",
    "        if (model_present == 'no'):\n",
    "            output_df, clf, best_parameter, best_model_name = mlClassificationPipeline(df, target)\n",
    "            #best_r2 = output_df['r_square_value'][0]\n",
    "        else:\n",
    "            clf = model_obj\n",
    "            output_df = 'temp'\n",
    "            #best_r2 = r2_score(df[target], model_obj.predict(df.drop(target, axis=1)))\n",
    "        # classification_simulation(df, target, 50000, reg)\n",
    "\n",
    "        generated_data, threshold_value, closeness, number_of_samples, model_value, deviation_histo, deviation_histo_original, y_pred_close, y_pred_close_filtered, true_percentage, constraints_dic, user_time = classification_simulation(\n",
    "               df, target, sample_size, clf, output_df, threshold_value, less_great)\n",
    "        type_of_problem = 'classification'\n",
    "        #st.write('before generated_data.columns: ', generated_data.columns)\n",
    "        #generated_data = undummify(generated_data)\n",
    "        #st.write('after generated_data.columns: ', generated_data.columns)\n",
    "\n",
    "    if(type_of_problem == 'classification'):\n",
    "        threshold_constraint = 0\n",
    "        min_value = 0\n",
    "        max_value = 0\n",
    "\n",
    "\n",
    "    memory_usage_process = tracemalloc.get_traced_memory()\n",
    "    print(\"RAM Usage [Bytes]: {}\".format(memory_usage_process[1]))\n",
    "    memory_usage.append(memory_usage_process)\n",
    "\n",
    "    tracemalloc.stop()\n",
    "    end = time.time()\n",
    "    total_time = end - begin - user_time\n",
    "    time_list.append(total_time)\n",
    "    #total_time += 403.0025112628937\n",
    "    print(\"Total time taken [Seconds]: {}\".format(total_time))\n",
    "\n",
    "    deviation_histo_original_df = pd.DataFrame()\n",
    "    deviation_histo_original_df['Deviation'] = deviation_histo_original\n",
    "    deviation_histo_original_df['hue'] = ['Positive Deviation' if x >= 0 else 'Negative Deviation' for x in deviation_histo_original ]\n",
    "    # plt.figure(figsize=(12,9))\n",
    "    plt.clf()\n",
    "    ax = sns.histplot(data=deviation_histo_original_df, x='Deviation', hue= 'hue', kde=True).set(\n",
    "          title=\"Positive and Negative Deviation from the estimation value \");\n",
    "    positive_samples = [x for x in deviation_histo_original if x >= 0]\n",
    "    negative_samples = [x for x in deviation_histo_original if x < 0]\n",
    "    positive_deviation = (len(positive_samples) / len(deviation_histo_original)) * 100\n",
    "    negative_deviation = (len(negative_samples) / len(deviation_histo_original)) * 100\n",
    "    plt.savefig(\"temp_image/Deviation.png\")\n",
    "\n",
    "    def plot_hist_regression():\n",
    "        plt.clf()\n",
    "\n",
    "        df_histo = pd.DataFrame({\"Predicted\": y_pred_close})\n",
    "        df_histo.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "        df_histo['Category'] = ['In-Range' if((i >= min_value) and (i <= max_value)) else 'Outside-Range' for i in y_pred_close]\n",
    "        df_histo.reset_index(drop=True, inplace=True)\n",
    "        #df_histo.to_csv('df_histo.csv', index= False)\n",
    "        #df_histo['Category'] = filtered_list\n",
    "        #st.write(\"min_value: \", min_value)\n",
    "        #st.write(\"max_value: \", max_value)\n",
    "        print(\"df_histo value count\", df_histo['Category'].value_counts())\n",
    "        #st.write(\"df_histo value count\", df_histo['Category'].value_counts())\n",
    "        #plt.figure(figsize=(7, 7))\n",
    "        #ax = sns.histplot(data=df_histo, x='Predicted', hue='Category', bins=50)\n",
    "        ax = sns.histplot(data=df_histo, x='Predicted', hue='Category')\n",
    "        fig = ax.get_figure()\n",
    "        fig.savefig(\"temp_image/Distribution.png\")\n",
    "        (n, bins, patches) = plt.hist(y_pred_close, bins=50)\n",
    "        n = n.tolist()\n",
    "        bins = bins.tolist()\n",
    "        lower_range = bins[n.index(max(n))]\n",
    "        upper_range = lower_range + ax.patches[1].xy[0] - ax.patches[0].xy[0]\n",
    "        highest_count = max(n)\n",
    "        ax.set_title(\"Distribution of the Synthetic Dataset from the Predictive Estimation\")\n",
    "        ax.set(xlabel='Predicted Values', ylabel='Count')\n",
    "\n",
    "        return lower_range, upper_range, highest_count\n",
    "\n",
    "    def plot_hist_classification():\n",
    "        plt.clf()\n",
    "        df_histo = pd.DataFrame({\"Predicted\": y_pred_close})\n",
    "        filtered_list = []\n",
    "        filtered_list.clear()\n",
    "        for num_data in y_pred_close:\n",
    "            if(less_great == 'Greater than'):\n",
    "                if num_data >= threshold_value:\n",
    "                    filtered_list.append('In-Range')\n",
    "                else:\n",
    "                    filtered_list.append('Outside-Range')\n",
    "            else:\n",
    "                if num_data <= threshold_value:\n",
    "                    filtered_list.append('In-Range')\n",
    "                else:\n",
    "                    filtered_list.append('Outside-Range')\n",
    "\n",
    "        df_histo['Category'] = filtered_list\n",
    "        print(df_histo['Category'].value_counts())\n",
    "        #palette = {\"In-Range\": \"C0\", \"Outside-Range\": \"C1\"}\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        ax = sns.histplot(data=df_histo, x='Predicted', hue='Category', bins=50)\n",
    "        ax.set_title(\"Distribution of the Synthetic Dataset from the Predictive Estimation\")\n",
    "        ax.set(xlabel='Predicted Probability (in percentage)', ylabel='Count');\n",
    "        fig = ax.get_figure()\n",
    "        fig.savefig(\"temp_image/Distribution.png\")\n",
    "\n",
    "        (n, bins, patches) = plt.hist(y_pred_close, bins=50)\n",
    "        n = n.tolist()\n",
    "        bins = bins.tolist()\n",
    "        lower_range = bins[n.index(max(n))]\n",
    "        upper_range = lower_range + ax.patches[1].xy[0] - ax.patches[0].xy[0]\n",
    "        highest_count = max(n)\n",
    "\n",
    "        return lower_range, upper_range, highest_count\n",
    "\n",
    "    if (type_of_problem == 'regression'):\n",
    "        lower_range, upper_range, highest_count = plot_hist_regression()\n",
    "    elif(type_of_problem == 'classification'):\n",
    "        lower_range, upper_range, highest_count = plot_hist_classification()\n",
    "\n",
    "    plt.clf()\n",
    "    #generated_data.dropna(axis=1, how= 'all', inplace = True)\n",
    "    #generated_data = generated_data.loc[:, (generated_data != 0).any(axis=0)]\n",
    "\n",
    "    phik_matrix = generated_data.phik_matrix()\n",
    "    #phik_matrix = generated_data.corr()\n",
    "    plt.figure(figsize=(13, 13))\n",
    "    heatmap_plot = sns.heatmap(phik_matrix, cmap='Blues', annot=True, linewidth=0.5, linecolor='black')\n",
    "    heatmap = heatmap_plot.get_figure()\n",
    "    heatmap.savefig(\"temp_image/Heatmap.png\")\n",
    "\n",
    "    # Current date and time calculation\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "    def set_bold(txt, h, pdf):\n",
    "        pdf.set_font('arial', 'B', 12)\n",
    "        pdf.write(h=h, txt=txt)\n",
    "        pdf.set_font('arial', '', 12)\n",
    "\n",
    "    def pdf_generate_regression(close_data):\n",
    "        pdf = FPDF('P', 'mm', 'A4')\n",
    "        pdf.add_page()\n",
    "        pdf.set_auto_page_break(True, margin=10)\n",
    "        pdf.accept_page_break()\n",
    "        pdf.set_font('arial', 'B', 15)\n",
    "        pdf.set_xy(20, 10)\n",
    "        pdf.cell(w=170, h=10, txt=\"PREDICTIVE ESTIMATION RISK REPORT\", border=0, ln=1, align='C', fill=False, link='')\n",
    "        pdf.cell(w=170, h=10, txt=\"Project: \"+project_name + \" - Date: \" + dt_string, border=0, ln=1, align='C', fill=False, link='')\n",
    "        pdf.set_font('arial', '', 12)\n",
    "        pdf.set_xy(10, 40)\n",
    "\n",
    "        pdf.write(h=7.5, txt=\"Objective of analysis: Estimate the value of target variable (\")\n",
    "        set_bold(target, 7.5, pdf)\n",
    "        pdf.write(h=7.5, txt=\") with target value (\")\n",
    "        set_bold(str(threshold_value), 7.5, pdf)\n",
    "        pdf.write(h=7.5, txt=\") with tolerance of minimum (\")\n",
    "        set_bold(str(min_value), 7.5, pdf)\n",
    "        pdf.write(h=7.5, txt=\"%) and maximum (\")\n",
    "        set_bold(str(max_value), 7.5, pdf)\n",
    "        pdf.write(h=7.5, txt=\"%)\")\n",
    "        pdf.ln(10)\n",
    "\n",
    "        pdf.write(h=7.5, txt=\"Target variable: \")\n",
    "        set_bold(target, 7.5, pdf)\n",
    "        pdf.ln(10)\n",
    "        # pdf.write(h=7.5, txt=\"Type of target variable: Numerical\")\n",
    "        pdf.write(h=7.5, txt=\"Target value: \")\n",
    "        set_bold(str(threshold_value), 7.5, pdf)\n",
    "        pdf.ln(10)\n",
    "        pdf.write(h=7.5, txt=\"Synthetic data size: \")\n",
    "        set_bold(str(number_of_samples), 7.5, pdf)\n",
    "        pdf.write(h=7.5, txt=\" rows\")\n",
    "        pdf.ln(10)\n",
    "\n",
    "        pdf.set_font('arial', 'B', 12)\n",
    "        pdf.ln(10)\n",
    "        if (len(constraints_dic) >= 1):\n",
    "            pdf.write(h=7.5, txt='Business rules applied during data creation - ')\n",
    "            pdf.ln(10)\n",
    "            pdf.set_font('arial', '', 12)\n",
    "            for i in constraints_dic.keys():\n",
    "                if i[-len(i):-1] == 'Between':\n",
    "                    set_bold(constraints_dic[i][0], 7.5, pdf)\n",
    "                    pdf.write(h=7.5, txt=\" (\")\n",
    "                    set_bold('Numerical', 7.5, pdf)\n",
    "                    pdf.write(h=7.5, txt=\" variable) - Used value range between \")\n",
    "                    set_bold(str(constraints_dic[i][1]), 7.5, pdf)\n",
    "                    pdf.write(h=7.5, txt=\" to \")\n",
    "                    set_bold(str(constraints_dic[i][2]), 7.5, pdf)\n",
    "                    pdf.ln(10)\n",
    "                elif i[-len(i):-1] == 'Categorical':\n",
    "                    set_bold(constraints_dic[i][1], 7.5, pdf)\n",
    "                    pdf.write(h=7.5, txt=\" (\")\n",
    "                    set_bold('Categorical', 7.5, pdf)\n",
    "                    pdf.write(h=7.5, txt=\" variable) - Used categories as \")\n",
    "                    set_bold(str(constraints_dic[i][0][0]), 7.5, pdf)\n",
    "                    pdf.write(h=7.5, txt=\",\")\n",
    "                    set_bold(str(constraints_dic[i][0][1]), 7.5, pdf)\n",
    "                    pdf.ln(10)\n",
    "        else:\n",
    "            pdf.write(h=7.5, txt='No business rules applied during data creation')\n",
    "            pdf.ln(10)\n",
    "\n",
    "        pdf.write(h=7.5, txt=\"Algorithms used in the synthetic data generation pipeline: \")\n",
    "        set_bold(\"Gaussian Copula Model, CTGAN Model, Copula GAN Model, TVAE\", 7.5, pdf)\n",
    "        pdf.ln(10)\n",
    "        pdf.write(h=7.5, txt=\"Algorithm which showed best closeness between real and synthetic dataset: \")\n",
    "        set_bold(str(model_value), 7.5, pdf)\n",
    "        pdf.ln(10)\n",
    "        pdf.write(txt=\"Percentage of closeness, using two-sample Kolmogorov Smirnov test: \", h=7.5)\n",
    "        set_bold(str(round(closeness)) + '% ', 7.5, pdf)\n",
    "        pdf.ln(10)\n",
    "\n",
    "        pdf.image(\"temp_image/Distribution.png\", x=50, w=110, h=100)\n",
    "        pdf.add_page()\n",
    "        pdf.set_xy(10, 20)\n",
    "\n",
    "        if (model_present == 'no'):\n",
    "            pdf.write(h=7.5, txt=\"Best performing model evaluated by Risk Analyzer: \")\n",
    "            set_bold(best_model_name, 7.5, pdf)\n",
    "            pdf.ln(5)\n",
    "            pdf.write(h=7.5, txt=\"Parameter used to create model: \")\n",
    "            set_bold(str(best_parameter), 7.5, pdf)\n",
    "            pdf.ln(5)\n",
    "\n",
    "        # set_bold(str(type_of_problem), 7.5, pdf)\n",
    "        pdf.write(txt=\"Model type: \", h=7.5)\n",
    "        set_bold(\"Regression\", 7.5, pdf)\n",
    "        pdf.ln(5)\n",
    "        pdf.write(txt=\"Total number of predictions made: \", h=7.5)\n",
    "        set_bold(str(number_of_samples), 7.5, pdf)\n",
    "        pdf.ln(5)\n",
    "        pdf.write(txt=\"Predictions in line with target range: \", h=7.5)\n",
    "        set_bold(str(round(positive_deviation, 2)), 7.5, pdf)\n",
    "        pdf.write(txt=\"%\", h=7.5)\n",
    "        pdf.ln(5)\n",
    "        pdf.write(txt=\"Predictions out of range: \", h=7.5)\n",
    "        set_bold(str(round(negative_deviation, 2)), 7.5, pdf)\n",
    "        pdf.write(txt=\"%\", h=7.5)\n",
    "        pdf.ln(5)\n",
    "\n",
    "        pdf.write(h=7.5, txt=\"The time taken to run the program is \")\n",
    "        set_bold(str(round(total_time, 2)), 7.5, pdf)\n",
    "        pdf.write(h=7.5, txt=\" seconds with a RAM usage of \")\n",
    "        set_bold(str(round(memory_usage_process[1])), 7.5, pdf)\n",
    "        pdf.write(h=7.5, txt=\" bytes.\")\n",
    "        for cols in close_data.columns:\n",
    "            plt.clf()\n",
    "            if (close_data[cols].dtype == 'object'):\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                sns_plot = sns.countplot(y=close_data[cols])\n",
    "                sns_plot.set(xlabel=cols, ylabel=\"Count\", title='Distribution of ' + cols)\n",
    "                fig = sns_plot.get_figure()\n",
    "                fig.savefig(\"temp_image/\"+cols + \".png\")\n",
    "\n",
    "            else:\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                sns_plot = sns.histplot(x=close_data[cols], kde=True)\n",
    "                sns_plot.set(xlabel=cols, ylabel=\"Count\")\n",
    "                fig = sns_plot.get_figure()\n",
    "                fig.savefig(\"temp_image/\"+cols + \".png\")\n",
    "\n",
    "                flag = 0\n",
    "            for cols in close_data.columns:\n",
    "                if (close_data[cols].dtype == object):\n",
    "                    flag = 1\n",
    "        for cols in close_data.columns:\n",
    "            pdf.add_page()\n",
    "            pdf.set_font('arial', 'B', 12)\n",
    "            pdf.write(h=7.5, txt=\"The distribution of \" + cols + \" evaluated for \" + str(number_of_samples) + \" synthetic data\")\n",
    "            pdf.set_font('arial', '', 12)\n",
    "            pdf.image(\"temp_image/\"+cols + '.png', x=30, y=25, w=100, h=100, type='', link='')\n",
    "            pdf.ln(120)\n",
    "            # pdf.cell(175, 10, \"Statistic: \", 0, 2, 'L')\n",
    "            if (close_data[cols].dtype == object):\n",
    "                pdf.cell(30, 10, 'Variable', 1, 0, 'C')\n",
    "                pdf.cell(30, 10, 'Count', 1, 0, 'C')\n",
    "                pdf.cell(30, 10, 'Percentage', 1, 1, 'C')\n",
    "                for i, item in enumerate(range(0, close_data[cols].value_counts().to_frame().shape[0])):\n",
    "                    var = close_data[cols].value_counts().to_frame().index.to_list()[i]\n",
    "                    count = close_data[cols].value_counts().to_frame()[cols].to_list()[i]\n",
    "                    percentage = close_data[cols].value_counts().to_frame()[cols].to_list()[i] * 100 / sum(\n",
    "                        close_data[cols].value_counts().to_frame()[cols].to_list())\n",
    "                    pdf.cell(30, 10, var, 1, 0, 'C')\n",
    "                    pdf.cell(30, 10, str(count), 1, 0, 'C')\n",
    "                    pdf.cell(30, 10, str(round(percentage, 2)), 1, 1, 'C')\n",
    "\n",
    "            else:\n",
    "                pdf.cell(175, 10, \"Min: \" + str(close_data[cols].min()), 0, 2, 'L')\n",
    "                pdf.cell(175, 10, \"Max: \" + str(close_data[cols].max()), 0, 2, 'L')\n",
    "                pdf.cell(175, 10, \"Average: \" + str(round(close_data[cols].mean(), 2)), 0, 2, 'L')\n",
    "\n",
    "        pdf.add_page()\n",
    "        pdf.set_xy(25, 10)\n",
    "        pdf.set_font('arial', 'B', 12)\n",
    "        pdf.write(h=7.5, txt='Correlation among variables using Phi_K for ' + str(number_of_samples) + ' data synthetic data: ')\n",
    "        pdf.image(\"temp_image/Heatmap.png\", x=10, y=25, w=200, h=200)\n",
    "        pdf.output('Predictive_Estimation_Report.pdf', 'F')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def pdf_generate_classification(close_data):\n",
    "\n",
    "        pdf = FPDF('P', 'mm', 'A4')\n",
    "        pdf.add_page()\n",
    "        pdf.set_auto_page_break(True, margin=10)\n",
    "        pdf.accept_page_break()\n",
    "        pdf.set_font('arial', 'B', 15)\n",
    "        pdf.set_xy(20, 10)\n",
    "        pdf.cell(w=170, h=10, txt=\"PREDICTIVE ESTIMATION RISK REPORT\", border=0, ln=1, align='C', fill=False, link='')\n",
    "        pdf.cell(w=170, h=10, txt=\"Project: \"+project_name + \" - Date: \" + dt_string, border=0, ln=1, align='C', fill=False, link='')\n",
    "        pdf.ln(10)\n",
    "        pdf.set_font('arial', '', 12)\n",
    "        pdf.set_xy(10, 40)\n",
    "        if(less_great == 'Greater than'):\n",
    "            pdf.write(h=7.5, txt=\"Objective of analysis: Estimate the probability for target variable (\")\n",
    "            set_bold(target, 7.5, pdf)\n",
    "            pdf.write(h=7.5, txt=\") being \")\n",
    "            set_bold('greater than', 7.5, pdf)\n",
    "            pdf.write(h=7.5, txt=\" the threshold value (\")\n",
    "            set_bold(str(threshold_value), 7.5, pdf)\n",
    "            pdf.write(h=7.5, txt=\"%)\")\n",
    "        elif(less_great == 'Less than'):\n",
    "            pdf.write(h=7.5, txt=\"Objective of analysis: Estimate the probability for target variable (\")\n",
    "            set_bold(target, 7.5, pdf)\n",
    "            pdf.write(h=7.5, txt=\") being\")\n",
    "            set_bold('less than', 7.5, pdf)\n",
    "            pdf.write(h=7.5, txt=\" the threshold value (\")\n",
    "            set_bold(str(threshold_value), 7.5, pdf)\n",
    "            pdf.write(h=7.5, txt=\"%)\")\n",
    "\n",
    "        pdf.ln(10)\n",
    "        pdf.write(h=7.5, txt=\"Target variable: \")\n",
    "        set_bold(target, 7.5, pdf)\n",
    "        pdf.ln(10)\n",
    "        #pdf.write(h=7.5, txt=\"Type of target variable: Categorical\")\n",
    "        pdf.write(h=7.5, txt=\"Target value: \")\n",
    "        set_bold(str(threshold_value), 7.5, pdf)\n",
    "        pdf.ln(10)\n",
    "        #set_bold(str(threshold_value), 7.5, pdf)\n",
    "        pdf.write(h=7.5, txt=\"Synthetic data size: \")\n",
    "        set_bold(str(number_of_samples), 7.5, pdf)\n",
    "        pdf.write(h=7.5, txt=\" rows\")\n",
    "        pdf.ln(10)\n",
    "        #pdf.write(h=7.5, txt=\" with a tolerance of ±\")\n",
    "        #set_bold(str(threshold_constraint), 7.5, pdf)\n",
    "        #pdf.write(h=7.5, txt=\"%, we produced a synthetic dataset of \")\n",
    "        #set_bold(str(number_of_samples), 7.5, pdf)\n",
    "        pdf.set_font('arial', 'B', 12)\n",
    "        pdf.ln(10)\n",
    "        #pdf.write(h=7.5, txt='Business rules applied during data creation - ')\n",
    "        #pdf.ln(10)\n",
    "        #pdf.set_font('arial', '', 12)\n",
    "        if (len(constraints_dic) >= 1):\n",
    "            pdf.write(h=7.5, txt='Business rules applied during data creation - ')\n",
    "            pdf.ln(10)\n",
    "            pdf.set_font('arial', '', 12)\n",
    "\n",
    "            for i in constraints_dic.keys():\n",
    "                if i[-len(i):-1] == 'Between':\n",
    "                    set_bold(constraints_dic[i][0], 7.5, pdf)\n",
    "                    pdf.write(h=7.5, txt=\" (\")\n",
    "                    set_bold('Numerical', 7.5, pdf)\n",
    "                    pdf.write(h=7.5, txt=\" variable) - value range between \")\n",
    "                    set_bold(str(constraints_dic[i][1]), 7.5, pdf)\n",
    "                    pdf.write(h=7.5, txt=\" to \")\n",
    "                    set_bold(str(constraints_dic[i][2]), 7.5, pdf)\n",
    "                    pdf.ln(10)\n",
    "                elif i[-len(i):-1] == 'Categorical':\n",
    "                    set_bold(constraints_dic[i][1], 7.5, pdf)\n",
    "                    pdf.write(h=7.5, txt=\" (\")\n",
    "                    set_bold('Categorical', 7.5, pdf)\n",
    "                    pdf.write(h=7.5, txt=\" variable) - Used categories as \")\n",
    "                    set_bold(str(constraints_dic[i][0][0]), 7.5, pdf)\n",
    "                    pdf.write(h=7.5, txt=\",\")\n",
    "                    set_bold(str(constraints_dic[i][0][1]), 7.5, pdf)\n",
    "                    pdf.ln(10)\n",
    "        else:\n",
    "            pdf.write(h=7.5, txt='No business rules applied during data creation')\n",
    "            pdf.ln(10)\n",
    "\n",
    "\n",
    "        pdf.write(h=7.5, txt=\"Algorithms used in the synthetic data generation pipeline: \")\n",
    "        set_bold(\"Gaussian Copula Model, CTGAN Model, Copula GAN Model, TVAE\", 7.5, pdf)\n",
    "        pdf.ln(10)\n",
    "        pdf.write(h=7.5, txt=\"Algorithm which showed best closeness between real and synthetic dataset: \")\n",
    "        set_bold(str(model_value), 7.5, pdf)\n",
    "        pdf.ln(10)\n",
    "        pdf.write(txt=\"Percentage of closeness, using two-sample Kolmogorov Smirnov test: \", h=7.5)\n",
    "        set_bold(str(round(closeness)) +'% ', 7.5, pdf)\n",
    "        pdf.ln(10)\n",
    "\n",
    "        pdf.image(\"temp_image/Distribution.png\", x=50, w=110, h=100)\n",
    "        pdf.add_page()\n",
    "        pdf.set_xy(10, 20)\n",
    "        #pdf.image(\"Deviation.png\", x=50, w=110, h=100)\n",
    "        #pdf.ln(5)\n",
    "\n",
    "        if(model_present == 'no'):\n",
    "            pdf.write(h=7.5, txt=\"Best performing model evaluated by Risk Analyzer: \")\n",
    "            set_bold(best_model_name, 7.5, pdf)\n",
    "            pdf.ln(5)\n",
    "            pdf.write(h=7.5, txt=\"Parameter used to create model: \")\n",
    "            set_bold(str(best_parameter), 7.5, pdf)\n",
    "            pdf.ln(5)\n",
    "\n",
    "        #set_bold(str(type_of_problem), 7.5, pdf)\n",
    "        pdf.write(txt=\"Model type: \", h=7.5)\n",
    "        set_bold(\"Classification\", 7.5, pdf)\n",
    "        pdf.ln(5)\n",
    "        #set_bold('model specification (which algorithm what are the hyperparameters etc.', 7.5, pdf)\n",
    "        pdf.write(txt=\"Total number of predictions made: \", h=7.5)\n",
    "        set_bold(str(number_of_samples), 7.5, pdf)\n",
    "        pdf.ln(5)\n",
    "        #set_bold(str(number_of_samples), 7.5, pdf)\n",
    "        pdf.write(txt=\"Predictions in line with target: \", h=7.5)\n",
    "        set_bold(str(round(positive_deviation,2)), 7.5, pdf)\n",
    "        pdf.write(txt=\"%\", h=7.5)\n",
    "        pdf.ln(5)\n",
    "        pdf.write(txt=\"Predictions out of range: \", h=7.5)\n",
    "        set_bold(str(round(negative_deviation, 2)), 7.5, pdf)\n",
    "        pdf.write(txt=\"%\", h=7.5)\n",
    "        pdf.ln(5)\n",
    "        #set_bold(str(number_of_samples), 7.5, pdf)\n",
    "        #pdf.write(h=7.5, txt=\" synthetic data points. Out of all predictive estimation, \")\n",
    "        #set_bold(str(round(true_percentage, 5)), 7.5, pdf)\n",
    "        #pdf.write(h=7.5, txt=\"% values are aligned with the user speculation. \")\n",
    "        #set_bold(str(round(negative_deviation, 2)), 7.5, pdf)\n",
    "        #pdf.write(h=7.5, txt=\"% of values are deviating negatively and \")\n",
    "        #set_bold(str(round(positive_deviation, 2)), 7.5, pdf)\n",
    "        #pdf.write(txt=\"% deviating positively\", h=7.5)\n",
    "        #pdf.ln(20)\n",
    "\n",
    "        pdf.write(h=7.5, txt=\"The time taken to run the program is \")\n",
    "        set_bold(str(round(total_time, 2)), 7.5, pdf)\n",
    "        pdf.write(h=7.5, txt=\" seconds with a RAM usage of \")\n",
    "        set_bold(str(round(memory_usage_process[1])), 7.5, pdf)\n",
    "        pdf.write(h=7.5, txt=\" bytes.\")\n",
    "        for cols in close_data.columns:\n",
    "            plt.clf()\n",
    "            if (close_data[cols].dtype == 'object'):\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns_plot = sns.countplot(y=close_data[cols])\n",
    "                sns_plot.set(xlabel=cols, ylabel=\"Count\", title='Distribution of ' + cols)\n",
    "                fig = sns_plot.get_figure()\n",
    "                fig.savefig(\"temp_image/\"+cols + \".png\")\n",
    "\n",
    "            else:\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                sns_plot = sns.histplot(x=close_data[cols], kde=True)\n",
    "                sns_plot.set(xlabel=cols, ylabel=\"Count\")\n",
    "                fig = sns_plot.get_figure()\n",
    "                fig.savefig(\"temp_image/\"+cols + \".png\")\n",
    "\n",
    "                flag = 0\n",
    "            for cols in close_data.columns:\n",
    "                if (close_data[cols].dtype == object):\n",
    "                    flag = 1\n",
    "        for cols in close_data.columns:\n",
    "            pdf.add_page()\n",
    "            pdf.set_font('arial', 'B', 12)\n",
    "            pdf.write(h=7.5, txt=\"The distribution of \" + cols + \" evaluated for \" + str(number_of_samples) + \" synthetic data\")\n",
    "            pdf.set_font('arial', '', 12)\n",
    "            pdf.image(\"temp_image/\"+cols + '.png', x=30, y=25, w=100, h=100, type='', link='')\n",
    "            pdf.ln(120)\n",
    "            #pdf.cell(175, 10, \"Statistic: \", 0, 2, 'L')\n",
    "            if (close_data[cols].dtype == object):\n",
    "                pdf.cell(30, 10, 'Variable', 1, 0, 'C')\n",
    "                pdf.cell(30, 10, 'Count', 1, 0, 'C')\n",
    "                pdf.cell(30, 10, 'Percentage', 1, 1, 'C')\n",
    "                for i, item in enumerate(range(0, close_data[cols].value_counts().to_frame().shape[0])):\n",
    "                    var = close_data[cols].value_counts().to_frame().index.to_list()[i]\n",
    "                    count = close_data[cols].value_counts().to_frame()[cols].to_list()[i]\n",
    "                    percentage = close_data[cols].value_counts().to_frame()[cols].to_list()[i] * 100 / sum(close_data[cols].value_counts().to_frame()[cols].to_list())\n",
    "                    pdf.cell(30, 10, var, 1, 0, 'C')\n",
    "                    pdf.cell(30, 10, str(count), 1, 0, 'C')\n",
    "                    pdf.cell(30, 10, str(round(percentage, 2)), 1, 1, 'C')\n",
    "\n",
    "            else:\n",
    "                pdf.cell(175, 10, \"Min: \" + str(close_data[cols].min()), 0, 2, 'L')\n",
    "                pdf.cell(175, 10, \"Max: \" + str(close_data[cols].max()), 0, 2, 'L')\n",
    "                pdf.cell(175, 10, \"Average: \" + str(round(close_data[cols].mean(), 2)), 0, 2, 'L')\n",
    "        pdf.add_page()\n",
    "        pdf.set_xy(25, 10)\n",
    "        pdf.set_font('arial', 'B', 12)\n",
    "        pdf.write(h=7.5, txt='Correlation among variables using Phi_K for ' + str(number_of_samples) + ' data synthetic data: ')\n",
    "        pdf.image(\"temp_image/Heatmap.png\", x=10, y=25, w=200, h=200)\n",
    "        pdf.output('Predictive_Estimation_Report.pdf', 'F')\n",
    "\n",
    "    if (type_of_problem == 'regression'):\n",
    "        pdf_generate_regression(generated_data)\n",
    "    elif(type_of_problem == 'classification'):\n",
    "        pdf_generate_classification(generated_data)\n",
    "\n",
    "    return memory_usage_process[1], total_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9e403d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf =  RandomizedSearchCV(cv=3, estimator=KNeighborsClassifier(), n_iter=25, n_jobs=-1,\n",
      "                   param_distributions={'algorithm': ['auto', 'ball_tree',\n",
      "                                                      'kd_tree', 'brute'],\n",
      "                                        'leaf_size': [30, 33, 36, 39, 42, 45,\n",
      "                                                      48, 51, 54, 57, 61, 64,\n",
      "                                                      67, 70, 73, 76, 79, 82,\n",
      "                                                      85, 88, 92, 95, 98, 101,\n",
      "                                                      104, 107, 110, 113, 116,\n",
      "                                                      120],\n",
      "                                        'metric': ['euclidean', 'manhattan',\n",
      "                                                   'chebyshev', 'minkowski',\n",
      "                                                   'wminkowski', 'seuclidean',\n",
      "                                                   'mahalanobis'],\n",
      "                                        'n_neighbors': [5, 17, 30, 42, 55],\n",
      "                                        'weights': ['uniform', 'distance']},\n",
      "                   random_state=42, scoring='roc_auc', verbose=2)\n",
      "type(clf) =  <class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "object\n",
      "<class 'numpy.dtype[object_]'>\n",
      "object\n",
      "<class 'numpy.dtype[object_]'>\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "float64\n",
      "<class 'numpy.dtype[float64]'>\n",
      "float64\n",
      "<class 'numpy.dtype[float64]'>\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "1 df_predicted[target_variable] 0         11.285582\n",
      "1         68.573325\n",
      "2        100.000000\n",
      "3        100.000000\n",
      "4        100.000000\n",
      "            ...    \n",
      "17437      0.000000\n",
      "17438      0.000000\n",
      "17439      0.000000\n",
      "17440      0.000000\n",
      "17441      0.000000\n",
      "Name: STATUS, Length: 17442, dtype: float64\n",
      "2 df_predicted_filtered[target_variable] 2        1\n",
      "3        1\n",
      "4        1\n",
      "5        1\n",
      "6        1\n",
      "        ..\n",
      "17210    1\n",
      "17211    1\n",
      "17261    1\n",
      "17262    1\n",
      "17263    1\n",
      "Name: STATUS, Length: 8163, dtype: int64\n",
      "For how many variables do you want to apply the constraint: 0\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "object\n",
      "<class 'numpy.dtype[object_]'>\n",
      "object\n",
      "<class 'numpy.dtype[object_]'>\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "float64\n",
      "<class 'numpy.dtype[float64]'>\n",
      "float64\n",
      "<class 'numpy.dtype[float64]'>\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "int64\n",
      "<class 'numpy.dtype[int64]'>\n",
      "\n",
      "Model Used: CTGAN\n",
      "Closeness to the real value dataset: 93.09%\n",
      "\n",
      "3 clf =  RandomizedSearchCV(cv=3, estimator=KNeighborsClassifier(), n_iter=25, n_jobs=-1,\n",
      "                   param_distributions={'algorithm': ['auto', 'ball_tree',\n",
      "                                                      'kd_tree', 'brute'],\n",
      "                                        'leaf_size': [30, 33, 36, 39, 42, 45,\n",
      "                                                      48, 51, 54, 57, 61, 64,\n",
      "                                                      67, 70, 73, 76, 79, 82,\n",
      "                                                      85, 88, 92, 95, 98, 101,\n",
      "                                                      104, 107, 110, 113, 116,\n",
      "                                                      120],\n",
      "                                        'metric': ['euclidean', 'manhattan',\n",
      "                                                   'chebyshev', 'minkowski',\n",
      "                                                   'wminkowski', 'seuclidean',\n",
      "                                                   'mahalanobis'],\n",
      "                                        'n_neighbors': [5, 17, 30, 42, 55],\n",
      "                                        'weights': ['uniform', 'distance']},\n",
      "                   random_state=42, scoring='roc_auc', verbose=2)\n",
      "3 type(clf) =  <class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "Estimated Risk calculated by the simulation program: 5.54%\n",
      "RAM Usage [Bytes]: 45801001\n",
      "Total time taken [Seconds]: 1075.6087982654572\n",
      "In-Range         47229\n",
      "Outside-Range     2771\n",
      "Name: Category, dtype: int64\n",
      "interval columns not set, guessing: ['SIZE', 'DISTANCE', 'DESIBEL', 'AIRFLOW', 'FREQUENCY']\n",
      "memory_usage =  45801001\n",
      "total_time =  1075.6087982654572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x648 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 936x936 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_to_file = 'Acoustic_Extinguisher_Fire_Dataset.csv'\n",
    "df = file_extension_read(path_to_file)\n",
    "target = 'STATUS' #'STATUS', 'Exited'\n",
    "sample_size = 50000\n",
    "threshold_value = 90 \n",
    "min_value = 0\n",
    "max_value = 0\n",
    "model_present = 'yes' #'yes', 'no'\n",
    "model_path = 'best_classification_model.pkl'\n",
    "model_obj = joblib.load(model_path)\n",
    "#model_obj = 'temp'\n",
    "problem_type = 'clf' #'reg'\n",
    "less_great = 'Greater than' #'Less than'\n",
    "project_name = 'Acoustic_Extinguisher_Fire_Dataset'\n",
    "\n",
    "memory_usage, total_time = start_process(df, target, sample_size, threshold_value, min_value, max_value, model_present, model_obj, less_great, project_name)\n",
    "print(\"memory_usage = \", memory_usage)\n",
    "print(\"total_time = \", total_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3a263f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score:  NA\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "For how many variables do you want to apply the constraint:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Used: GaussianCopula\n",
      "Closeness to the real value dataset: 79.67%\n",
      "\n",
      "Estimated Risk calculated by the simulation program: 91.98%\n",
      "RAM Usage [Bytes]: 21846297\n",
      "Total time taken [Seconds]: 37.585527420043945\n",
      "df_histo value count Outside-Range    35843\n",
      "In-Range         14157\n",
      "Name: Category, dtype: int64\n",
      "interval columns not set, guessing: ['House_Age', 'Nearest_Station', 'Convenience_Stores', 'Latitude', 'Longitude']\n",
      "memory_usage =  21846297\n",
      "total_time =  37.585527420043945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x648 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 936x936 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_to_file = 'house_price.csv'\n",
    "df = file_extension_read(path_to_file)\n",
    "target = 'House_Price'\n",
    "sample_size = 50000\n",
    "threshold_value = 30\n",
    "min_value = -5\n",
    "max_value = 5\n",
    "model_present = 'yes' #'yes', 'no'\n",
    "model_path = 'best_regression_model.pkl'\n",
    "model_obj = joblib.load(model_path)\n",
    "#model_obj = 'temp'\n",
    "problem_type = 'reg'\n",
    "less_great = 'null'\n",
    "project_name = 'House Price Prediction'\n",
    "\n",
    "memory_usage, total_time = start_process(df, target, sample_size, threshold_value, min_value, max_value, model_present, model_obj, less_great, project_name)\n",
    "print(\"memory_usage = \", memory_usage)\n",
    "print(\"total_time = \", total_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf0d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154bb5d3-b1a4-4a92-b208-5c4d566b8b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d81734-e51b-485c-8628-df403e932a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a5ba0-6397-4cf1-9fb6-0275249fb1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da2b53-35c3-4be4-adb1-845166bfb4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (Intel® oneAPI)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
